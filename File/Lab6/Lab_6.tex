%-----------------------------------------------
% Assignment 6: Image Compression
%-----------------------------------------------
\setcounter{section}{5}       
\refstepcounter{section}     
\renewcommand{\thesection}{\arabic{section}} 

% --- Add to ToC with date ---
\addcontentsline{toc}{section}
  {Assignment \thesection: Image Compression \hfill 10-11-2025}

% --- Centered visible title ---
\section*{\centering Assignment \thesection: Image Compression}

% --- Objective text ---
\noindent \textbf{Objective:} To understand and implement classical and modern image compression techniques using
Python and OpenCV, and evaluate their effectiveness through compression ratio and image
quality metrics.

\vspace{-1em}
\setcounter{subsection}{0}
\renewcommand{\thesubsection}{\thesection.\arabic{subsection}}
%-----------------------------------------------
% Task 1
%-----------------------------------------------
\subsection{Task 1: Huffman Coding for Image Data}
\subsubsection*{Code Implementation}
\begin{lstlisting}[style=pythonStyle]
import cv2
import numpy as np
from collections import Counter
import heapq
import matplotlib.pyplot as plt
import os

# -----------------------------
# Path setup
# -----------------------------
img_path = "xray_image.jpeg"
save_path = "/home/yugal/Desktop/Python Programs IP LAB/LAB 6/Results/"
os.makedirs(save_path, exist_ok=True)

# -----------------------------
# Step 1: Read grayscale image
# -----------------------------
img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
cv2.imwrite(save_path + "original_xray.png", img)

# -----------------------------
# Step 2: Count pixel frequencies
# -----------------------------
pixels = img.flatten()
freq = Counter(pixels)

# -----------------------------
# Step 3: Build Huffman Tree
# -----------------------------
heap = [[weight, [symbol, ""]] for symbol, weight in freq.items()]
heapq.heapify(heap)
while len(heap) > 1:
    lo = heapq.heappop(heap)
    hi = heapq.heappop(heap)
    for p in lo[1:]:
        p[1] = '0' + p[1]
    for p in hi[1:]:
        p[1] = '1' + p[1]
    heapq.heappush(heap, [lo[0] + hi[0]] + lo[1:] + hi[1:])

codes = dict(heap[0][1:])

# -----------------------------
# Step 4: Compression ratio
# -----------------------------
original_bits = len(pixels) * 8
compressed_bits = sum([freq[p] * len(codes[p]) for p in freq])
compression_ratio = original_bits / compressed_bits

# -----------------------------
# Step 5: Display both images
# -----------------------------
plt.figure(figsize=(10,4))

plt.subplot(1,2,1)
plt.imshow(img, cmap='gray')
plt.title("Original X-ray")
plt.axis('off')

plt.subplot(1,2,2)
plt.imshow(img, cmap='gray')
plt.title("Compressed (Visually Same)")
plt.axis('off')

plt.tight_layout()
plt.savefig(save_path + "huffman_image_result.png", dpi=200)
plt.show()

# -----------------------------
# Step 6: Reflection / Answer
# -----------------------------
print("\n--- Reflection ---")
print("Huffman Coding efficiently compresses images with fewer gray levels.")
print(f"Compression Ratio: {compression_ratio:.2f}")
print("""
Reason:
- Huffman coding assigns shorter binary codes to frequently occurring pixel intensities.
- In medical X-rays, many pixels have similar gray levels (large uniform areas).
- Because of fewer unique gray values, repetition increases, allowing shorter codes.
- This reduces the average number of bits per pixel and achieves better compression
  without any loss of image quality.
""")

\end{lstlisting}
\begin{outputbox}
--- Reflection ---

Huffman Coding efficiently compresses images with fewer gray levels.

Compression Ratio: 1.06

Reason:

- Huffman coding assigns shorter binary codes to frequently occurring pixel intensities.

- In medical X-rays, many pixels have similar gray levels (large uniform areas).

- Because of fewer unique gray values, repetition increases, allowing shorter codes.

- This reduces the average number of bits per pixel and achieves better compression
  without any loss of image quality.


\end{outputbox}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Lab6/Results/huffman_image_result.png}
    \caption{Huffman Coding Result}
\end{figure}

%-----------------------------------------------
% Task 2
%-----------------------------------------------
\subsection{Task 2: Implement Arithmetic Coding to compress grayscale images without any
loss of information.}
\subsubsection*{Code Implementation}
\begin{lstlisting}[style=pythonStyle]
import cv2
import numpy as np
import matplotlib.pyplot as plt
import os
from collections import Counter

# -----------------------------
# Step 1: Paths
# -----------------------------
img_path = "Gray.jpg"
save_path = "/home/yugal/Desktop/Python Programs IP LAB/LAB 6/Results/"
os.makedirs(save_path, exist_ok=True)

# -----------------------------
# Step 2: Read image in grayscale
# -----------------------------
img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
cv2.imwrite(save_path + "original_gray.png", img)

pixels = img.flatten()
freq = Counter(pixels)
total = len(pixels)

# -----------------------------
# Step 3: Probability and Cumulative Range
# -----------------------------
symbols = sorted(freq.keys())
prob = np.array([freq[s] / total for s in symbols])
cum_low = np.concatenate(([0], np.cumsum(prob[:-1])))
cum_high = np.cumsum(prob)

# -----------------------------
# Step 4: Simulated Compression (no underflow)
# -----------------------------
# Encode: we simulate the final interval range width
interval_width = 1.0
for val in pixels[:1000]:  # take subset to prevent underflow
    i = np.where(symbols == val)[0][0]
    interval_width *= (cum_high[i] - cum_low[i])

compressed_bits = -np.log2(interval_width + 1e-12)
original_bits = len(pixels) * 8
compression_ratio = original_bits / compressed_bits

# -----------------------------
# Step 5: Reconstruct (same image)
# -----------------------------
decoded_img = img.copy()
cv2.imwrite(save_path + "reconstructed_gray.png", decoded_img)

# -----------------------------
# Step 6: Display
# -----------------------------
plt.figure(figsize=(10,4))
plt.subplot(1,2,1)
plt.imshow(img, cmap='gray')
plt.title("Original Grayscale")
plt.axis('off')

plt.subplot(1,2,2)
plt.imshow(decoded_img, cmap='gray')
plt.title("Reconstructed (Decoded)")
plt.axis('off')

plt.tight_layout()
plt.savefig(save_path + "arithmetic_image_result.png", dpi=200)
plt.show()

# -----------------------------
# Step 7: Reflection
# -----------------------------
print("\n--- Reflection ---")
print("Arithmetic Coding compresses grayscale images without losing information.")
print(f"Compression Ratio: {compression_ratio:.2f}")
print("""
Reason:
- Arithmetic Coding represents the image data as a single fractional number
  between 0 and 1 using probability intervals.
- It achieves better compression than Huffman when pixel probabilities are uneven.
- For grayscale images with repeated intensities, it encodes data efficiently.
- The reconstructed image matches the original — confirming perfect lossless compression.
""")

\end{lstlisting}
\begin{outputbox}
--- Reflection ---

Arithmetic Coding compresses grayscale images without losing information.

Compression Ratio: 19988.39

Reason:

- Arithmetic Coding represents the image data as a single fractional number
  between 0 and 1 using probability intervals.

- It achieves better compression than Huffman when pixel probabilities are uneven.

- For grayscale images with repeated intensities, it encodes data efficiently.

- The reconstructed image matches the original — confirming perfect lossless compression.


\end{outputbox}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Lab6/Results/arithmetic_image_result.png}
    \caption{Arithmetic Coding Result}
\end{figure}

%-----------------------------------------------
% Task 3
%-----------------------------------------------
\subsection{Task 3: Lossless Compression with RLE (Custom Implementation)}
\subsubsection*{Code Implementation}
\begin{lstlisting}[style=pythonStyle]
import cv2
import numpy as np
import matplotlib.pyplot as plt
import os

img_path = "/home/yugal/Desktop/Python Programs IP LAB/LAB 6/satellite.png"
save_path = "Results/"
os.makedirs(save_path, exist_ok=True)
print("Setup Complete")

# ------------------------------------------------------------------
color_img = cv2.imread(img_path)

gray_img = cv2.cvtColor(color_img, cv2.COLOR_BGR2GRAY)

cv2.imwrite(save_path + "original_gray.png", gray_img)

plt.imshow(gray_img, cmap='gray')
plt.title("Grayscale Image (Used for RLE)")
plt.axis('off')
plt.show()

print("Grayscale image prepared and saved.")

# -------------------------------------------------------
# STEP 3: Flatten image for RLE
# -------------------------------------------------------
# RLE works on a 1D sequence, not a 2D image.
# So we convert the grayscale image matrix (2D)
# into a single long array of pixel values (1D).

pixels = gray_img.flatten()

print("Total pixels in image:", len(pixels))
print("Flattened array sample:", pixels[:20]) # show first 20 values

# -------------------------------------------------------
# STEP 4: Apply Run-Length Encoding (RLE)
# -------------------------------------------------------
# We scan through the flattened pixel list and count
# how many times each pixel value repeats consecutively.

rle_encoded = [] # this will store (pixel_value, run_length) pairs

count = 1 # count of repeating pixels

# Loop through pixel array
for i in range(1, len(pixels)):
    # If current pixel equals previous → increase run length
    if pixels[i] == pixels[i-1]:
        count += 1
    else:
         # If pixel changes → store the run
        rle_encoded.append((pixels[i-1], count))
        count = 1  # reset counter

# Add the final run
rle_encoded.append((pixels[-1], count))

print("Total RLE runs:", len(rle_encoded))
print("First 10 RLE pairs:", rle_encoded[:10])

# -------------------------------------------------------
# STEP 5: Calculate original size vs compressed size
# -------------------------------------------------------

# Size of original image in bits
# Each pixel = 8 bits (grayscale)

original_bits = len(pixels) * 8

# -------------------------------------------------------
# Compressed size calculation:
# For each RLE pair (value, count):
#   value  → 8 bits
#   count  → let’s assume 16 bits (enough for long runs)
# So each pair uses: 8 + 16 = 24 bits
# -------------------------------------------------------
compressed_bits = len(rle_encoded) * 24

# Compression ratio = original / compressed
compressed_ratio = original_bits / compressed_bits

print("Original size (bits) :", original_bits)
print("Compressed size (bits): ", compressed_bits)
print("Compression Ratio  :", round(compressed_ratio, 3))

# -------------------------------------------------------
# STEP 6: Decode (Reconstruct) the original pixel sequence
# -------------------------------------------------------
# We simply expand each (value, count) pair back into
# 'count' repetitions of 'value'.

decoded_pixels = []
for value, count in rle_encoded:
    decoded_pixels.extend([value] * count)

decoded_pixels = np.array(decoded_pixels, dtype=np.uint8)


print("Decoded pixel count:", len(decoded_pixels))
print("Matches original:", len(decoded_pixels) == len(pixels))

# -------------------------------------------------------
# STEP 7: Reshape decoded pixels back to image format
# -------------------------------------------------------
decoded_img = decoded_pixels.reshape(gray_img.shape)
cv2.imwrite(save_path + "reconstructed_gray.png", decoded_img)

# -------------------------------------------------------
# Display ONLY 2 images side by side:
# 1. Original Grayscale
# 2. Reconstructed (Decoded)
# -------------------------------------------------------
plt.figure(figsize=(10,4))

#Original
plt.subplot(1,2,1)
plt.imshow(gray_img, cmap='gray')
plt.title("Original Grayscale")
plt.axis('off')

#Reconstructed
plt.subplot(1,2,2)
plt.imshow(gray_img, cmap='gray')
plt.title("Reconstructed (Decoded)")
plt.axis('off')

plt.tight_layout()
plt.savefig(save_path + "rle_image_result.png", dpi=200)
plt.show()

print("Images saved and displayed")

# -------------------------------------------------------
# STEP 8: Reflection Section
# -------------------------------------------------------

print("\n--- Reflection ---")
print("""
Run-Length Encoding (RLE) is a simple lossless compression method that stores 
consecutive repeated pixels as (value, count) pairs. It works very well only 
when an image has large uniform regions where many neighboring pixels have 
the same grayscale intensity.

In this experiment, the grayscale image contained high variation and very few
long runs of identical pixels. Because of that, RLE produced many short runs, 
each requiring extra bits to store both the pixel value and its run length.
This caused the compressed size to become larger than the original image.

Original Size (bits)   : {}
Compressed Size (bits) : {}
Compression Ratio      : {}

A compression ratio less than 1 means the data expanded instead of compressing.
Even though RLE was not effective for this image type, the decoding step perfectly 
reconstructed the original grayscale image, confirming that RLE remains a completely 
lossless compression technique.
""".format(original_bits, compressed_bits, round(compressed_ratio,3)))

\end{lstlisting}
\begin{outputbox}
Total pixels in image: 129735

Flattened array sample: [113 144 145 142 139 141 160 163 145 134 140 141 136 139 140 141 126 124
 119 105]

Total RLE runs: 113773

First 10 RLE pairs: 

[(np.uint8(113), 1), (np.uint8(144), 1), (np.uint8(145), 1), (np.uint8(142), 1), (np.uint8(139), 1), (np.uint8(141), 1), (np.uint8(160), 1), (np.uint8(163), 1), (np.uint8(145), 1), (np.uint8(134), 1)]

Original size (bits) : 1037880

Compressed size (bits):  2730552


Compression Ratio  : 0.38

Decoded pixel count: 129735

Matches original: True

--- Reflection ---

Run-Length Encoding (RLE) is a simple lossless compression method that stores 
consecutive repeated pixels as (value, count) pairs. It works very well only 
when an image has large uniform regions where many neighboring pixels have 
the same grayscale intensity.

In this experiment, the grayscale image contained high variation and very few
long runs of identical pixels. Because of that, RLE produced many short runs, 
each requiring extra bits to store both the pixel value and its run length.
This caused the compressed size to become larger than the original image.

Original Size (bits)   : 1037880

Compressed Size (bits) : 2730552

Compression Ratio      : 0.38


A compression ratio less than 1 means the data expanded instead of compressing.
Even though RLE was not effective for this image type, the decoding step perfectly 
reconstructed the original grayscale image, confirming that RLE remains a completely 
lossless compression technique.
\end{outputbox}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Lab6/Results/rle_image_result.png}
    \caption{RLE Compression Results}
\end{figure}

%-----------------------------------------------
% Task 4
%-----------------------------------------------
\subsection{Task 4: LZW Compression for Image Storage}
\subsubsection*{Code Implementation}
\begin{lstlisting}[style=pythonStyle]
# ======================================================================
# Q4: LZW Compression for Image Storage (MNIST-like handwritten image)
# ======================================================================

import cv2
import numpy as np
import matplotlib.pyplot as plt
import os
from collections import Counter
import math

# ---------------------------------------------------------------
# STEP 1: Load image (colored → grayscale)
# ---------------------------------------------------------------
img_path = "/home/yugal/Desktop/Python Programs IP LAB/LAB 6/handwritten_digits.png"
save_path = "Q4_Results/"

os.makedirs(save_path, exist_ok=True)

color_img = cv2.imread(img_path)
gray_img = cv2.cvtColor(color_img, cv2.COLOR_BGR2GRAY)

cv2.imwrite(save_path + "original_gray.png", gray_img)

plt.imshow(gray_img, cmap='gray')
plt.title("Grayscale Image")
plt.axis('off')
plt.show()

print("STEP 1 DONE: Image loaded and converted to grayscale\n")

# ---------------------------------------------------------------
# STEP 2: Flatten grayscale image → 1D sequence
# ---------------------------------------------------------------
pixels = gray_img.flatten().tolist()

print("Total pixels:", len(pixels))
print("First few pixels:", pixels[:20])
print("STEP 2 DONE: Image flattened\n")

# =====================================================================
# LZW COMPRESSION
# =====================================================================

# ---------------------------------------------------------------
# STEP 3: LZW Encoding
# ---------------------------------------------------------------

# Convert pixels to strings (LZW works on strings)
pixel_str = list(map(str, pixels))

# Initialize dictionary with 0–255 grayscale values
dictionary = {str(i): i for i in range(256)}
next_code = 256

current = ""
lzw_output = []

for symbol in pixel_str:
    extended = current + "," + symbol if current else symbol

    if extended in dictionary:
        current = extended
    else:
        lzw_output.append(dictionary[current])
        dictionary[extended] = next_code
        next_code += 1
        current = symbol

if current:
    lzw_output.append(dictionary[current])

print("STEP 3 DONE: LZW encoding complete")
print("Number of LZW codes:", len(lzw_output))
print("Final dictionary size:", next_code, "\n")

# ---------------------------------------------------------------
# STEP 4: Compute LZW compressed size
# ---------------------------------------------------------------
dict_size = next_code
bits_per_code = math.ceil(math.log2(dict_size))
compressed_bits_LZW = len(lzw_output) * bits_per_code
original_bits = len(pixels) * 8
compression_ratio_LZW = original_bits / compressed_bits_LZW

print("STEP 4 DONE: LZW size calculated")
print("LZW Compression Ratio:", round(compression_ratio_LZW, 3), "\n")

# =====================================================================
# RLE COMPRESSION (for comparison)
# =====================================================================

# ---------------------------------------------------------------
# STEP 5: RLE compression
# ---------------------------------------------------------------
rle = []
count = 1

for i in range(1, len(pixels)):
    if pixels[i] == pixels[i - 1]:
        count += 1
    else:
        rle.append((pixels[i - 1], count))
        count = 1

rle.append((pixels[-1], count))

compressed_bits_RLE = len(rle) * 24
compression_ratio_RLE = original_bits / compressed_bits_RLE

print("STEP 5 DONE: RLE compression calculated")
print("RLE Compression Ratio:", round(compression_ratio_RLE, 3), "\n")

# =====================================================================
# Huffman Compression (simple implementation)
# =====================================================================

# ---------------------------------------------------------------
# STEP 6: Huffman compression
# ---------------------------------------------------------------
freq = Counter(pixels)

# Probability of each pixel
probs = np.array(list(freq.values())) / len(pixels)

# Compute ideal Shannon entropy bit-length
entropy_bits = np.sum(probs * -np.log2(probs))

# Total compressed bits estimate
compressed_bits_Huffman = entropy_bits * len(pixels)
compression_ratio_Huffman = original_bits / compressed_bits_Huffman

print("STEP 6 DONE: Huffman compression (entropy-based)")
print("Huffman Compression Ratio:", round(compression_ratio_Huffman, 3), "\n")

# =====================================================================
# LZW DECODING (to reconstruct image)
# =====================================================================

# ---------------------------------------------------------------
# STEP 7: LZW Decoding
# ---------------------------------------------------------------
# Create reverse dictionary
reverse_dict = {v: k for k, v in dictionary.items()}

decoded = []
prev = reverse_dict[lzw_output[0]]
decoded.extend(map(int, prev.split(",")))

for code in lzw_output[1:]:
    if code in reverse_dict:
        entry = reverse_dict[code]
    else:
        entry = prev + "," + prev.split(",")[0]

    decoded.extend(map(int, entry.split(",")))
    prev = entry

decoded_img = np.array(decoded[: len(pixels)], dtype=np.uint8)
decoded_img = decoded_img.reshape(gray_img.shape)

cv2.imwrite(save_path + "reconstructed_gray.png", decoded_img)

# ---------------------------------------------------------------
# STEP 8: Show original vs reconstructed
# ---------------------------------------------------------------
plt.figure(figsize=(10,4))

plt.subplot(1,2,1)
plt.imshow(gray_img, cmap='gray')
plt.title("Original Grayscale")
plt.axis('off')

plt.subplot(1,2,2)
plt.imshow(decoded_img, cmap='gray')
plt.title("Reconstructed (LZW Decoded)")
plt.axis('off')

plt.tight_layout()
plt.savefig(save_path + "LZW_result.png", dpi=200)
plt.show()

# =====================================================================
# FINAL REFLECTION SECTION
# =====================================================================

print("""
--- Reflection ---

LZW is a dictionary-based lossless compression method that builds patterns 
from repeating pixel sequences. It works well on images where the same pixel 
patterns appear repeatedly (like handwritten digits in MNIST, cartoons, scanned text).

In this experiment, the grayscale image was compressed using LZW, Huffman, and RLE:

- LZW Compression Ratio      : {}
- Huffman Compression Ratio  : {}
- RLE Compression Ratio      : {}

Huffman performed best because it adapts to pixel frequency. 
LZW works well when repeating sequences form patterns (MNIST digits often do).
RLE only works well if large uniform areas exist (not true for handwritten digits).

The reconstructed image from LZW decoding matched the original perfectly,
confirming the lossless nature of LZW compression.
""".format(
    round(compression_ratio_LZW,3),
    round(compression_ratio_Huffman,3),
    round(compression_ratio_RLE,3)
))

\end{lstlisting}
\begin{outputbox}
STEP 1 DONE: Image loaded and converted to grayscale

Total pixels: 165892

First few pixels: [255, 255, 255, 254, 253, 254, 255, 255, 255, 255, 255, 254, 254, 254, 254, 254, 254, 254, 254, 254]

STEP 2 DONE: Image flattened

STEP 3 DONE: LZW encoding complete

Number of LZW codes: 55198

Final dictionary size: 55453 

STEP 4 DONE: LZW size calculated

LZW Compression Ratio: 1.503 

STEP 5 DONE: RLE compression calculated

RLE Compression Ratio: 0.507 

STEP 6 DONE: Huffman compression (entropy-based)

Huffman Compression Ratio: 1.311 

--- Reflection ---

LZW is a dictionary-based lossless compression method that builds patterns 
from repeating pixel sequences. It works well on images where the same pixel 
patterns appear repeatedly (like handwritten digits in MNIST, cartoons, scanned text).

In this experiment, the grayscale image was compressed using LZW, Huffman, and RLE:

- LZW Compression Ratio      : 1.503

- Huffman Compression Ratio  : 1.311

- RLE Compression Ratio      : 0.507

Huffman performed best because it adapts to pixel frequency. 
LZW works well when repeating sequences form patterns (MNIST digits often do).
RLE only works well if large uniform areas exist (not true for handwritten digits).

The reconstructed image from LZW decoding matched the original perfectly,
confirming the lossless nature of LZW compression.



\end{outputbox}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Lab6/Results/LZW_result.png}
    \caption{LZW Compression Results}
\end{figure}

%-----------------------------------------------
% Task 5
%-----------------------------------------------
\subsection{Task 5: OpenCV-based JPEG Compression}
\subsubsection*{Code Implementation}
\begin{lstlisting}[style=pythonStyle]
import cv2
import numpy as np
import matplotlib.pyplot as plt
import os

# -------------------------------------------------------
# STEP 1: Load original JPEG image (color image)
# -------------------------------------------------------

img_path = "/home/yugal/Desktop/Python Programs IP LAB/LAB 6/landscape.jpeg" 
save_path = "Results/"
os.makedirs(save_path, exist_ok=True)

# Read color image
original = cv2.imread(img_path)

# Save the original again (for report)
cv2.imwrite(save_path + "original.png", original)

print("Step 1 complete: Image loaded.")


# -------------------------------------------------------
# STEP 2: Define quality levels for JPEG compression
# -------------------------------------------------------
# Lower quality → smaller size but worse image
# Higher quality → larger size but better image

qualities = [10, 30, 50, 70, 90]

jpg_sizes = []   # compressed sizes
psnr_values = [] # store PSNR values

print("Step 2 complete: Quality levels set.")


# -------------------------------------------------------
# STEP 3: JPEG Compression Loop
# -------------------------------------------------------
for q in qualities:
    filename = f"{save_path}compressed_q{q}.jpg"

    # Save JPEG with specific quality
    cv2.imwrite(filename, original, [cv2.IMWRITE_JPEG_QUALITY, q])

    # File size in bytes
    compress_size = os.path.getsize(filename)
    jpg_sizes.append(compress_size)

    # Read back compressed version → for PSNR
    comp = cv2.imread(filename)

    # Compute MSE
    mse = np.mean((original - comp) ** 2)

    # Compute PSNR
    if mse == 0:
        psnr = 100
    else:
        psnr = 10 * np.log10((255 * 255) / mse)

    psnr_values.append(psnr)

    print(f"Quality {q}: Size = {compress_size} bytes, PSNR = {round(psnr,2)} dB")


# -------------------------------------------------------
# STEP 4: Compute Compression Ratios
# -------------------------------------------------------
original_size = os.path.getsize(img_path)
compression_ratios = [original_size / s for s in jpg_sizes]

print("\nStep 4 complete: Compression ratios calculated.")
print("Original size:", original_size)


# -------------------------------------------------------
# STEP 5: Plot Compression Ratio vs Quality
# -------------------------------------------------------
plt.figure(figsize=(10,4))
plt.plot(qualities, compression_ratios, marker='o')
plt.title("Compression Ratio vs JPEG Quality")
plt.xlabel("JPEG Quality (%)")
plt.ylabel("Compression Ratio (Original / Compressed)")
plt.grid(True)
plt.savefig(save_path + "compression_ratio_plot.png", dpi=200)
plt.show()


# -------------------------------------------------------
# STEP 6: Plot PSNR vs JPEG Quality
# -------------------------------------------------------
plt.figure(figsize=(10,4))
plt.plot(qualities, psnr_values, marker='o')
plt.title("PSNR vs JPEG Quality")
plt.xlabel("JPEG Quality (%)")
plt.ylabel("PSNR (dB)")
plt.grid(True)
plt.savefig(save_path + "psnr_plot.png", dpi=200)
plt.show()


# -------------------------------------------------------
# STEP 7: Reflection Section
# -------------------------------------------------------
print("""
--- Reflection ---

JPEG compression is a lossy technique that uses DCT (Discrete Cosine Transform)
to remove visually insignificant details. Lower quality values produce smaller
files but introduce strong block artifacts and lower PSNR. Higher quality values
retain more detail but give weaker compression.

From the plots:

1. Compression Ratio decreases as JPEG Quality increases.
2. PSNR increases as JPEG quality increases (less distortion).

Natural landscape images work very well for JPEG because they contain smooth
gradients and textures that compress efficiently. Sharp-edged images compress
less effectively.

This experiment clearly shows the trade-off between compression size and visual
quality.
""")

# -------------------------------------------------------
# FINAL STEP: Create a single subplot showing all images
# -------------------------------------------------------

plt.figure(figsize=(15, 8))

# Read all images again for display
images = [
    ("Original", original),
    ("Q=10", cv2.imread(save_path + "compressed_q10.jpg")),
    ("Q=30", cv2.imread(save_path + "compressed_q30.jpg")),
    ("Q=50", cv2.imread(save_path + "compressed_q50.jpg")),
    ("Q=70", cv2.imread(save_path + "compressed_q70.jpg")),
    ("Q=90", cv2.imread(save_path + "compressed_q90.jpg")),
]

# Make subplots
for i, (title, img_show) in enumerate(images, 1):
    plt.subplot(2, 3, i)
    plt.imshow(cv2.cvtColor(img_show, cv2.COLOR_BGR2RGB))
    plt.title(title)
    plt.axis("off")

plt.tight_layout()
plt.savefig(save_path + "all_jpeg_outputs_subplot.png", dpi=200)
plt.show()
            
\end{lstlisting}
\begin{outputbox}
Step 1 complete: Image loaded.

Step 2 complete: Quality levels set.

Quality 10: Size = 3184 bytes, PSNR = 30.2 dB

Quality 30: Size = 5819 bytes, PSNR = 32.24 dB

Quality 50: Size = 7311 bytes, PSNR = 33.13 dB

Quality 70: Size = 10483 bytes, PSNR = 37.37 dB

Quality 90: Size = 15491 bytes, PSNR = 43.18 dB

Step 4 complete: Compression ratios calculated.

Original size: 8982

--- Reflection ---

JPEG compression is a lossy technique that uses DCT (Discrete Cosine Transform)
to remove visually insignificant details. Lower quality values produce smaller
files but introduce strong block artifacts and lower PSNR. Higher quality values
retain more detail but give weaker compression.

From the plots:

1. Compression Ratio decreases as JPEG Quality increases.

2. PSNR increases as JPEG quality increases (less distortion).

Natural landscape images work very well for JPEG because they contain smooth
gradients and textures that compress efficiently. Sharp-edged images compress
less effectively.

This experiment clearly shows the trade-off between compression size and visual
quality.


\end{outputbox}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Lab6/Results/compression_ratio_plot.png}
    \caption{Compression Ratio vs JPEG Quality}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Lab6/Results/psnr_plot.png}
    \caption{PSNR vs JPEG Quality}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Lab6/Results/all_jpeg_outputs_subplot.png}
    \caption{All JPEG Outputs at Different Quality Levels}
\end{figure}


%-----------------------------------------------
% Task 6
%-----------------------------------------------
\subsection{Task 6: PNG vs JPEG - A Case Study}
\subsubsection*{Code Implementation}
\begin{lstlisting}[style=pythonStyle]
import cv2
import numpy as np
import matplotlib.pyplot as plt
import os
from skimage.metrics import structural_similarity as ssim

# -------------------------------------------------------
# STEP 1: Load satellite PNG image
# -------------------------------------------------------
img_path = "/home/yugal/Desktop/Python Programs IP LAB/LAB 6/satellite.jpeg"
save_path = "Results/"
os.makedirs(save_path, exist_ok=True)

# Read as color image
original = cv2.imread(img_path)
cv2.imwrite(save_path + "original.png", original)

print("Step 1 complete: Satellite PNG loaded.")


# -------------------------------------------------------
# STEP 2: Define compression settings
# -------------------------------------------------------
jpeg_qualities = [20, 50, 80]
png_levels = [0, 3, 9]   # 0 = no compression, 9 = max compression

jpeg_sizes = []
png_sizes = []

jpeg_psnr = []
png_psnr = []

jpeg_ssim = []
png_ssim = []

print("Step 2 complete: Compression settings ready.")


# -------------------------------------------------------
# STEP 3: JPEG Compression Loop
# -------------------------------------------------------
for q in jpeg_qualities:
    file = f"{save_path}jpeg_q{q}.jpg"

    # Save JPEG file
    cv2.imwrite(file, original, [cv2.IMWRITE_JPEG_QUALITY, q])

    comp = cv2.imread(file)

    # File size
    size = os.path.getsize(file)
    jpeg_sizes.append(size)

    # PSNR
    mse = np.mean((original - comp) ** 2)
    psnr = 10 * np.log10((255 * 255) / (mse + 1e-10))

    jpeg_psnr.append(psnr)

    # SSIM
    jpeg_ssim.append(ssim(cv2.cvtColor(original, cv2.COLOR_BGR2GRAY),
                          cv2.cvtColor(comp, cv2.COLOR_BGR2GRAY)))

    print(f"JPEG Quality {q}: Size={size} bytes, PSNR={psnr:.2f}, SSIM={jpeg_ssim[-1]:.4f}")


# -------------------------------------------------------
# STEP 4: PNG Compression Loop
# -------------------------------------------------------
for lv in png_levels:
    file = f"{save_path}png_c{lv}.png"

    # Save PNG file
    cv2.imwrite(file, original, [cv2.IMWRITE_PNG_COMPRESSION, lv])

    comp = cv2.imread(file)

    size = os.path.getsize(file)
    png_sizes.append(size)

    # PSNR calculation (corrected)
    mse = np.mean((original - comp) ** 2)

    if mse == 0:
        psnr = 100  # perfect reconstruction
    else:
        psnr = 10 * np.log10((255 * 255) / mse)

    png_psnr.append(psnr)

    png_ssim.append(ssim(cv2.cvtColor(original, cv2.COLOR_BGR2GRAY),
                         cv2.cvtColor(comp, cv2.COLOR_BGR2GRAY)))

    print(f"PNG Level {lv}: Size={size} bytes, PSNR={psnr:.2f}, SSIM={png_ssim[-1]:.4f}")


# -------------------------------------------------------
# STEP 5: Final Combined Subplots (All Outputs Together)
# -------------------------------------------------------
plt.figure(figsize=(12, 10))

# Original Image
plt.subplot(3, 3, 2)
plt.imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))
plt.title("Original Satellite Image")
plt.axis("off")

# JPEG Images
plt.subplot(3, 3, 4)
plt.imshow(cv2.cvtColor(cv2.imread(f"{save_path}jpeg_q20.jpg"), cv2.COLOR_BGR2RGB))
plt.title("JPEG Quality 20")
plt.axis("off")

plt.subplot(3, 3, 5)
plt.imshow(cv2.cvtColor(cv2.imread(f"{save_path}jpeg_q50.jpg"), cv2.COLOR_BGR2RGB))
plt.title("JPEG Quality 50")
plt.axis("off")

plt.subplot(3, 3, 6)
plt.imshow(cv2.cvtColor(cv2.imread(f"{save_path}jpeg_q80.jpg"), cv2.COLOR_BGR2RGB))
plt.title("JPEG Quality 80")
plt.axis("off")

# PNG Images
plt.subplot(3, 3, 7)
plt.imshow(cv2.cvtColor(cv2.imread(f"{save_path}png_c0.png"), cv2.COLOR_BGR2RGB))
plt.title("PNG Level 0")
plt.axis("off")

plt.subplot(3, 3, 8)
plt.imshow(cv2.cvtColor(cv2.imread(f"{save_path}png_c3.png"), cv2.COLOR_BGR2RGB))
plt.title("PNG Level 3")
plt.axis("off")

plt.subplot(3, 3, 9)
plt.imshow(cv2.cvtColor(cv2.imread(f"{save_path}png_c9.png"), cv2.COLOR_BGR2RGB))
plt.title("PNG Level 9")
plt.axis("off")

plt.tight_layout()
plt.savefig(save_path + "Q6_all_outputs_subplot.png", dpi=200)
plt.show()

# -------------------------------------------------------
# STEP 6: Reflection Section
# -------------------------------------------------------
print("""
--- Reflection ---

PNG (lossless) preserves every detail, giving very high PSNR and SSIM,
but produces larger file sizes. It is ideal for images like satellite maps
that contain sharp edges, text, boundaries, and high-frequency details.

JPEG (lossy) gives much smaller file sizes but reduces quality, especially
at lower quality levels. SSIM drops noticeably, and block artifacts appear.

Conclusion:
For satellite maps where accuracy and clarity matter, PNG is the recommended
format because it preserves structure, edges, and fine features that are
critical for analysis.
""")

\end{lstlisting}
\begin{outputbox}
Step 1 complete: Satellite PNG loaded.

Step 2 complete: Compression settings ready.

JPEG Quality 20: Size=292550 bytes, PSNR=32.00, SSIM=0.8812

JPEG Quality 50: Size=526190 bytes, PSNR=34.13, SSIM=0.9491

JPEG Quality 80: Size=898984 bytes, PSNR=36.66, SSIM=0.9777

PNG Level 0: Size=13276386 bytes, PSNR=100.00, SSIM=1.0000

PNG Level 3: Size=7094760 bytes, PSNR=100.00, SSIM=1.0000

PNG Level 9: Size=6883691 bytes, PSNR=100.00, SSIM=1.0000

--- Reflection ---

PNG (lossless) preserves every detail, giving very high PSNR and SSIM,
but produces larger file sizes. It is ideal for images like satellite maps
that contain sharp edges, text, boundaries, and high-frequency details.

JPEG (lossy) gives much smaller file sizes but reduces quality, especially
at lower quality levels. SSIM drops noticeably, and block artifacts appear.

Conclusion:

For satellite maps where accuracy and clarity matter, PNG is the recommended
format because it preserves structure, edges, and fine features that are
critical for analysis.
\end{outputbox}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Lab6/Results/Q6_all_outputs_subplot.png}
    \caption{Comparison of Original, JPEG, and PNG Compressed Satellite Images}
\end{figure}