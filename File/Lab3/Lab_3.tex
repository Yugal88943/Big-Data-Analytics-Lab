% Assignment 3: Apply distributed computing concepts using MapReduce.
%-----------------------------------------------
\refstepcounter{section}
\addlabcontentsline{Assignment \thesection: Implement MapReduce programs for Data Processing.}
{(10-02-2026)}
{\thepage}      
\section*{\centering Assignment \thesection: Implement MapReduce programs for Data Processing.}

\noindent \textbf{Objective:} Apply distributed computing concepts by implementing a MapReduce program in Hadoop to process data efficiently across distributed nodes.

%-----------------------------------------------
% Step 1
%-----------------------------------------------
\subsection{Step 1: Start Hadoop Services}

\begin{verbatim}
su - hadoop
start-dfs.sh
start-yarn.sh
jps
\end{verbatim}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{Lab3/Images/start_services.png}
    \caption{Starting Hadoop services and verifying with jps}
    \label{fig:start_services}
\end{figure}

%-----------------------------------------------
% Step 2
%-----------------------------------------------
\subsection{Step 2: Create Input Directory in HDFS}

\begin{verbatim}
nano input.txt
ls
cat input.txt
hdfs dfs -mkdir /input
hdfs dfs -put input.txt /input
hdfs dfs -ls /input
\end{verbatim}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{Lab3/Images/hdfs_input.png}
    \caption{Creating input directory and uploading dataset}
    \label{fig:hdfs_input}
\end{figure}

%-----------------------------------------------
% Step 3
%-----------------------------------------------
\subsection{Step 3: Write MapReduce Program}

\noindent\textbf{Mapper Class:} Processes input data and generates intermediate key-value pairs.
\begin{verbatim}
nano Mapper.java
\end{verbatim}
\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{Lab3/Images/mapper.png}
    \caption{Mapper class implementation}
    \label{fig:mapper}
\end{figure}
\noindent\textbf{Reducer Class:} Aggregates values for each key produced by the mapper.
\begin{verbatim}
nano Reducer.java
\end{verbatim}
\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{Lab3/Images/reducer.png}
    \caption{Reducer class implementation}
    \label{fig:reducer}
\end{figure}
\noindent\textbf{Driver Class:} Configures job parameters such as input/output paths, mapper, reducer, and execution settings.
\begin{verbatim}
nano Driver.java
\end{verbatim}
\begin{figure}[H]
    \vspace{-1em}
    \centering
    \includegraphics[width=1.0\textwidth]{Lab3/Images/driver.png}
    \caption{Driver class implementation}
    \label{fig:driver}
\end{figure}

%-----------------------------------------------
% Step 4
%-----------------------------------------------
\subsection{Step 4: Compile Program and Create JAR}

\begin{verbatim}
javac -classpath `hadoop classpath` -d . Mapper.java Reducer.java Driver.java
jar -cvf wordcount.jar *.class
\end{verbatim}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{Lab3/Images/compile.png}
    \caption{Compilation and JAR creation}
    \label{fig:compile}
\end{figure}

%-----------------------------------------------
% Step 5
%-----------------------------------------------
\subsection{Step 5: Execute MapReduce Job}

\begin{verbatim}
hadoop jar wordcount.jar Driver /input /output
\end{verbatim}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{Lab3/Images/run_job.png}
    \caption{Executing MapReduce job}
    \label{fig:run_job}
\end{figure}

%-----------------------------------------------
% Step 6
%-----------------------------------------------
\subsection{Step 6: Check Output Directory in HDFS}

\begin{verbatim}
hdfs dfs -ls /output
\end{verbatim}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{Lab3/Images/output_dir.png}
    \caption{Output directory created in HDFS}
    \label{fig:output_dir}
\end{figure}

%-----------------------------------------------
% Step 7
%-----------------------------------------------
\subsection{Step 7: Display Result File}

\begin{verbatim}
hdfs dfs -cat /mapreduce_output/part-r-00000
\end{verbatim}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{Lab3/Images/result.png}
    \caption{Displaying MapReduce output}
    \label{fig:result}
\end{figure}

%-----------------------------------------------
% Step 8
%-----------------------------------------------
\subsection{Step 8: Modify Input and Re-run Job}

\begin{verbatim}
nano input.text
hdfs dfs -put input.txt /input
hdfs dfs -rm -r /output
hadoop jar wordcount.jar Driver /input /output
hdfs dfs -cat /output/part-r-00000
\end{verbatim}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{Lab3/Images/updatetext.png}
    \caption{Updating input text file}
    \label{fig:updatetext}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{Lab3/Images/rerun.png}
    
    \caption{Re-running MapReduce with modified dataset}
    \label{fig:rerun}
\end{figure}
\begin{figure}[H]
    \centering
   \includegraphics[width=1.0\textwidth]{Lab3/Images/rerun1.png}
    \caption{New output after re-running MapReduce job}
    \label{fig:new_output}
\end{figure}

%-----------------------------------------------
% Result
%-----------------------------------------------
\subsection{Result}

\noindent The MapReduce job was successfully executed on Hadoop. Input data stored in HDFS was processed using Mapper and Reducer classes, and the output was generated in the HDFS output directory. Re-running the job with modified input demonstrated changes in output based on data size and content.

%-----------------------------------------------
% Conclusion
%-----------------------------------------------
\subsection{Conclusion}
 
\noindent This assignment demonstrated the practical implementation of the MapReduce programming model in Hadoop. It showed how distributed computing enables scalable data processing by dividing tasks into mapping and reducing phases, improving efficiency for large datasets.
